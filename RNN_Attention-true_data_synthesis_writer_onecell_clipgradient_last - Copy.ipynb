{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "from random import choice, randrange\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime as dt\n",
    "import io\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-probability==0.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user tensorflow==2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#tf.debugging.enable_check_numerics()\n",
    "#tf.config.set_visible_devices([], 'GPU') \n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(121)\n",
    "tf.random.set_seed(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_URL = \"C:/Users/Youssef/workspacePy/data_source/medicament_data/med_output2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_med_csv(filename):\n",
    "    l_med=[]\n",
    "    with open(filename, 'r',encoding=\"utf-8\" ,newline='') as f:\n",
    "        lis = f.readlines()\n",
    "        \n",
    "        for  i ,line in enumerate(lis):\n",
    "            if i == 0 :\n",
    "                continue\n",
    "            \n",
    "            record = line.strip()\n",
    "           \n",
    "            l_med.append(record.capitalize()+' ')     \n",
    "                \n",
    "    return l_med    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2378\n",
      "Ervevax\n"
     ]
    }
   ],
   "source": [
    "med_ds = read_med_csv(TRAIN_DATA_URL)\n",
    "print(len(set(med_ds)))\n",
    "med_ds = list(set(med_ds))\n",
    "print(med_ds[1524].strip())\n",
    "#med_ds[0] = 'The Shawshank Redemption '\n",
    "# med_ds[1] = 'Doliprane 500 '\n",
    "# med_ds[2] = 'Augmentin 1g '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_med_to_num = [[drawing.alpha_to_num[ch] for ch in me]  for me in med_ds]\n",
    "real_seqs = [tf.convert_to_tensor(li )  for li in list_med_to_num]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(real_seqs[1524])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\x00', ' ', '!', '\"', '%', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(drawing.alphabet)\n",
    "vocab_size = len( drawing.alphabet )\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 76)\n"
     ]
    }
   ],
   "source": [
    "#load real_seqs from seved npy file (real_seqs_medicament2_saved.npy)to conserve the same order of words\n",
    "\n",
    "   # real_seqs = [tf.one_hot(tf.cast(line , dtype = \"int32\") , vocab_size) for line in real_seqs ]\n",
    "   # print(real_seqs[0].shape)\n",
    "real_seqs = np.load('real_seqs_medicament2_saved.npy' , allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_seqs = np.load('real_seqs_medicament2_saved.npy' , allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_weight = 'true_data+layerGMM_Q_Z_16_writer_cholski_timedistributed_oneCell_clipGradient' # for trained weights go to folder : true_data+layerGMM'\n",
    "\n",
    "path_tosave_image = 'my_handwriting_true_data_writer_oneCell_clipgradient/'\n",
    "\n",
    "vocab_size = len( drawing.alphabet )\n",
    "\n",
    "units = 400\n",
    "k_mixture = 10\n",
    "GMM_mixtures = 20\n",
    "\n",
    "seq_length = 1\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "lst_alpha = []\n",
    "lst_logprob = []\n",
    "\n",
    "\n",
    "epochs =50\n",
    "take_batch =725\n",
    "custom_period = 20\n",
    "first_log = True\n",
    "periodic_log = False\n",
    "last_batch = False\n",
    "number_of_writer = 198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2378"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(real_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class lstm_attention_layer(tf.keras.layers.Layer):\n",
    " def __init__(self ,num_cells , kmixtures ):\n",
    "      super(lstm_attention_layer , self).__init__()\n",
    "#       self.dense_attention = tf.keras.layers.Dense(kmixtures * 3 , activation=tf.nn.softplus,\n",
    "#                                                    kernel_initializer = tf.initializers.GlorotUniform(31))#,input_shape =(BATCH_SIZE,seq_length) )\n",
    "      \n",
    "      self.lstm = tf.keras.layers.LSTMCell(num_cells, name='lstm_1')\n",
    "        \n",
    "        \n",
    "     \n",
    "        \n",
    "      self.dense_attention_a= tf.keras.layers.Dense(kmixtures * 3 , activation=tf.keras.activations.softplus,\n",
    "                                )\n",
    "\n",
    "    \n",
    "      self.mixtures = kmixtures\n",
    "     \n",
    "      self.state_size = [num_cells, num_cells , vocab_size , kmixtures]\n",
    "        \n",
    "      \n",
    "# @tf.function       \n",
    " def call (self , inpu, states ,constants ):\n",
    "      global last_batch\n",
    "      global periodic_log\n",
    "      \n",
    "    \n",
    "    \n",
    "      prev_h_lstm, prev_c_lstm, prev_w , prev_kappa = states\n",
    "\n",
    "      lstm_out, lstm_states = self.lstm(tf.concat([inpu, prev_w], axis=-1), (prev_h_lstm, prev_c_lstm))\n",
    "      h_lstm, c_lstm = lstm_states\n",
    "        \n",
    "     \n",
    "      character_seq = constants[0]#tf.concat( [tf.zeros( (BATCH_SIZE ,char_real_seqs , 1)), whitout_zero] , axis = -1)\n",
    "      #print('character_seq reduce++++++++++++++++++++++++++++++++' ,character_seq )#tf.reduce_sum(character_seq , axis = -1))\n",
    "      #print('where_zero' , whitout_zero)\n",
    "      \n",
    "      #out_dense = self.dense_attention(tf.concat( [inputs ,states[0] ] ,-1))\n",
    "      #alpha, beta, kappa   = tf.split(out_dense, 3 ,1)\n",
    "      \n",
    "      inputs = tf.concat( [inpu,lstm_out ,constants[1] ] ,-1)\n",
    "      window_out = self.dense_attention_a( inputs )#(BS , kmixtures * 3  )\n",
    "      alpha , beta , kappa =  tf.split(window_out, 3, -1)\n",
    "#       alpha = self.dense_attention_a( inputs )#(BS , kmixtures  )\n",
    "#       beta = self.dense_attention_b(inputs)#(BS , kmixtures  )\n",
    "\n",
    "#       kappa = self.dense_attention_k(inputs )#(BS , kmixtures  ) \n",
    "     \n",
    "      if  periodic_log :\n",
    "            print('inputs to attention cell after concat' , inputs )\n",
    "            print(\"constants to attention cell :constants[0] shape\" ,constants[0].shape)\n",
    "            print('states [2]' ,states[2])\n",
    "            print('states [3]' ,states[3])\n",
    "            print('kappa ' , kappa) \n",
    "            print('beta '   , beta )\n",
    "            print('alpha '  , alpha)\n",
    "      kappa_t = prev_kappa + kappa   # states[3] - kappa \n",
    "       \n",
    "      beta_t  =  tf.clip_by_value( beta, .01, 1000 )#tfp.math.clip_by_value_preserve_gradient( beta, .01, 1000 )\n",
    "      alpha_t =  tf.clip_by_value(alpha, .01, 1000)\n",
    "      \n",
    "      window , phi = self.get_window(alpha_t, beta_t, kappa_t ,character_seq) \n",
    "      new_phi.assign(tf.cast (tf.math.argmax(tf.squeeze(phi) ,axis = 0 ), tf.int32 ))\n",
    "      \n",
    "      #phi_track.append(phi) \n",
    "      #char_track.append(drawing.alphabet[tf.math.argmax(window [0]).numpy().astype(np.int32)] )  \n",
    "       \n",
    "          \n",
    "    \n",
    "    \n",
    "      #self.window.assign(window)\n",
    "      return  (window ,lstm_out ),[ h_lstm, c_lstm , window , kappa_t ]  \n",
    "\n",
    " def get_window(self , alpha, beta, kappa ,seq ):\n",
    "    # phi -> [? x 1 x ascii_steps] and is a tf matrix\n",
    "    # c -> [? x ascii_steps x alphabet] and is a tf matrix\n",
    "     ascii_steps = seq.get_shape()[0]  #.value #number of items in sequence\n",
    "    # print(\"ascii_steps\" , ascii_steps)   \n",
    "     \n",
    "     phi = self.get_phi(ascii_steps, alpha, beta, kappa)# phi.shape = (BZ,c.seq,1)\n",
    "    \n",
    "    \n",
    "     window = tf.multiply(phi,seq)\n",
    "     \n",
    "     window = tf.reduce_sum(window , 1) # window ~ [?,alphabet]\n",
    "     #print(\"window shape after reduce sum: window[0]\" , window )\n",
    "     if periodic_log :  \n",
    "        print(\"window shape after reduce sum: window[0]\" , window )\n",
    "        print(\"c      [0]: \" , seq[0] )\n",
    "        \n",
    "     return window , phi\n",
    " \n",
    "#get phi for all t,u (returns a [1 x tsteps] matrix) that defines the window\n",
    " def get_phi(self ,ascii_steps, alpha, beta, kappa):\n",
    "        \n",
    "        \n",
    "    u = tf.linspace(1.0,tf.dtypes.cast(ascii_steps, tf.float32),ascii_steps )# weight all the U items in the sequence\n",
    "    u = tf.expand_dims(u , 0)\n",
    "    u = tf.expand_dims(u , 0)       #(1, 1, ascii_steps)\n",
    "    u = tf.tile( u , (BATCH_SIZE , self.mixtures , 1))  #(BZ, MIX , ascii_steps)\n",
    "   \n",
    "          \n",
    "    kappa = tf.expand_dims(kappa,2) \n",
    "    beta = tf.expand_dims(beta,2)\n",
    "    alpha = tf.expand_dims(alpha,2)\n",
    "    phi = alpha * tf.math.exp(tf.math.negative(beta) * tf.math.square(kappa - u))\n",
    "    \n",
    "    phi = tf.reduce_sum(phi,1, keepdims=True)\n",
    "\n",
    "    return tf.reshape( phi ,(BATCH_SIZE ,ascii_steps ,1) )  #  [BS,ascii_steps ,1]\n",
    "    \n",
    " def get_initial_state(self ,inputs, batch_size , dtype):\n",
    "   \n",
    "      h_lstm, c_lstm = self.lstm.get_initial_state(inputs, batch_size, dtype)\n",
    "    \n",
    "        # to initial kappa value eguals the length of the sequence\n",
    "      window = tf.zeros((batch_size,vocab_size) , dtype = 'float32')\n",
    "      init_kappa  = tf.zeros((batch_size,self.mixtures) , dtype = 'float32')  \n",
    "      return[h_lstm, c_lstm , window , init_kappa]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM_layer(tf.keras.layers.Layer):\n",
    " def __init__(self ,GMM_mixtures):\n",
    "      super(GMM_layer , self).__init__()\n",
    "      \n",
    "#param : activation=tf.nn.relu .will be changed depending on the data set values\n",
    "#make 'seq_length'param  not hard_coded\n",
    "      #self.bernoulli0  = tf.keras.layers.Dense(4, activation=tf.nn.sigmoid)\n",
    "      self.bernoulli  = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1,\n",
    "                                              activation=tf.nn.sigmoid , name = 'bernoulli'))\n",
    "      \n",
    "      self.alpha     = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(\n",
    "                              GMM_mixtures,name = 'alpha'))\n",
    "      self.mu_x      = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(\n",
    "                                              GMM_mixtures,name = 'mu_s'))#weight.shape(64,20)=>(input,gmm)\n",
    "      self.mu_y      = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(\n",
    "                                              GMM_mixtures,name= 'mu_y'))\n",
    "      self.sigma_x   = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(\n",
    "                                              GMM_mixtures,name ='sigma_x'))\n",
    "      self.sigma_y   = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(\n",
    "                                            GMM_mixtures,name='sigma_y'))\n",
    "      self.corr      = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(\n",
    "                                            GMM_mixtures, \n",
    "                                             activation=tf.nn.tanh,name = 'corr'))\n",
    "     \n",
    "      \n",
    " def call(self ,inpt ,mask=None ):\n",
    "    \n",
    "    \n",
    "     self.bernoullis = self.bernoulli(inpt)\n",
    "     \n",
    "    \n",
    "     \n",
    "     self.alpha_s         =  tf.nn.softmax(self.alpha(inpt) ) \n",
    "    \n",
    "     self.mu_x_s    = self.mu_x(inpt) #(32,1200,20) =>(batch,seq.length,gmm)\n",
    "     self.mu_y_s    = self.mu_y(inpt)\n",
    "     #print('self.bernoulli.get_weights()',np.asarray(self.bernoulli.trainable_variables)[0])\n",
    "   \n",
    "     self.sigma_xs        =  tf.nn.softplus(self.sigma_x(inpt) - segma_bias)\n",
    "     self.sigma_ys        =  tf.nn.softplus(self.sigma_y(inpt) - segma_bias)\n",
    "    \n",
    "     self.corr_s    = self.corr(inpt)\n",
    "#      print('self.mu_x_s .shape',self.mu_x_s)\n",
    "#      print('self.mu_y_s .shape',self.mu_y_s)   \n",
    "    \n",
    "     self.bernoulli_distribution = tfd.Bernoulli(probs = self.bernoullis)\n",
    "     \n",
    "     self.bi_gaussian = bivariate_gaussian( self.mu_x_s, self.mu_y_s,\n",
    "                                           self.sigma_xs ,self.sigma_ys , self.corr_s ,self.alpha_s )\n",
    "     if  periodic_log :\n",
    "        print('gmm + berll concat',tf.concat([self.bi_gaussian.sample() , \n",
    "                       tf.cast(self.bernoulli_distribution.sample(),tf.float32)],axis = -1)[0:1,:,:]\n",
    "            )\n",
    "     self.prediction =  tf.concat([self.bi_gaussian.sample() , \n",
    "                tf.cast(self.bernoulli_distribution.sample(),tf.float32)],axis = -1)\n",
    "     \n",
    "     lst_alpha.append(self.alpha_s)\n",
    "     lst_logprob .append( self.bi_gaussian.mvd.prob(self.prediction[: ,: ,0:2]))  \n",
    "     return self.prediction\n",
    " \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bivariate_gaussian():\n",
    "    \n",
    "   def __init__(self , mu1, mu2, sigma1, sigma2, rho, alpha ):\n",
    "    self. mu1   =  mu1\n",
    "    self. mu2   =  mu2\n",
    "    self.sigma1 =  sigma1\n",
    "    self.sigma2 =  sigma2\n",
    "    self.rho = rho\n",
    "    self.alpha = alpha\n",
    "    \n",
    "    \n",
    "    mu  = tf.stack([self.mu1 ,self.mu2] ,axis = -1)   \n",
    "    \n",
    "    #print('periodic_log from logprob1',periodic_log)\n",
    "    if  periodic_log :\n",
    "       print('mu' , mu)\n",
    "    sq1 = self.sigma1*self.sigma1\n",
    "    if  periodic_log :\n",
    "       print('self.sigma1' , self.sigma1)\n",
    "\n",
    "    sq2 = self.sigma2*self.sigma2\n",
    "    if  periodic_log :\n",
    "        print('self.sigma2' , self.sigma2)\n",
    "\n",
    "    co = self.rho*self.sigma1*self.sigma2\n",
    "    if  periodic_log :\n",
    "        print('co',co)\n",
    "\n",
    "    row = tf.stack([sq1 , co,co ,sq2] ,axis = -1)\n",
    "    if  periodic_log :\n",
    "        print('row     ' ,row)\n",
    "    self.mvd = tfd.MixtureSameFamily(mixture_distribution=tfd.Categorical(probs=self.alpha),\n",
    "                                 components_distribution = tfp.distributions.MultivariateNormalTriL(\n",
    "                                                                   mu,\n",
    "                       tf.linalg.cholesky(tf.reshape(row ,(BATCH_SIZE ,seq_length ,GMM_mixtures,2,2)))))\n",
    "    \n",
    "  \n",
    "  \n",
    "   def sample (self) :\n",
    "    global periodic_log\n",
    "\n",
    "\n",
    "    smpl =self.mvd.sample()\n",
    "\n",
    "    if  periodic_log :\n",
    "        print('smpl' ,smpl[0:5,:,:])\n",
    "    return smpl \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnn_model(tf.keras.Model):\n",
    "    def __init__(self , enc_units, batch_sz ,kmixtures ,GMM_mixtures  ):\n",
    "        super(rnn_model , self).__init__()\n",
    "       \n",
    "        \n",
    "       # self.lstm11           = Lstm1(  enc_units, batch_sz)\n",
    "        self. mask_layer      =  tf.keras.layers.Masking(mask_value=0.,batch_input_shape=(BATCH_SIZE , seq_length, 3))\n",
    "   \n",
    "        self.lstm_attention_cell   = lstm_attention_layer(enc_units , kmixtures)\n",
    "        #self.attention_cell.initial_state()\n",
    "        self.lstm_att  = tf.keras.layers.RNN(\n",
    "                                     self.lstm_attention_cell ,stateful = True, return_sequences=True ) \n",
    "        #self.rnn              = tf.keras.layers.RNN(self.attention_cell ,  return_sequences=True )\n",
    "        self.l1 = tf.keras.layers.LSTM(enc_units ,return_sequences = True, \n",
    "                                       stateful = True,recurrent_initializer=tf.initializers.GlorotUniform(21),\n",
    "                                      kernel_initializer=tf.initializers.GlorotUniform(22))\n",
    "        self.l2 = tf.keras.layers.LSTM(enc_units ,return_sequences = True,\n",
    "                                       stateful = True,recurrent_initializer=tf.initializers.GlorotUniform(23),\n",
    "                                      kernel_initializer=tf.initializers.GlorotUniform(24))\n",
    "  \n",
    "        #self.lstm22           =   Lstm2(  enc_units )\n",
    "        \n",
    "        self.gm_layer         = GMM_layer(GMM_mixtures)\n",
    "        \n",
    "    def call (self , inpt ,seq_writer ):\n",
    "       \n",
    "#          global periodic_log\n",
    "#          global first_log\n",
    "#          global last_batch\n",
    "        \n",
    "         \n",
    "#          if first_log:\n",
    "#             print(\"inpt shape\" , inpt.shape)  \n",
    "         \n",
    "#          start = timer()  \n",
    "            \n",
    "#          prev_window = self.attention_cell.return_window() \n",
    "         \n",
    "#          concat_inp = tf.concat([inpt,tf.tile(tf.expand_dims(prev_window,1),(1,1000,1) )] , axis = -1)\n",
    "#          out1 ,mask   =   self.lstm11(concat_inp)\n",
    "#          end = timer()\n",
    "#         # print('lstm1 duration' ,end - start )\n",
    "        \n",
    "#          if first_log:\n",
    "#             print(\"l1 x shape\" , out1.shape)  \n",
    "            \n",
    "         start = timer() \n",
    "         input_mask =  self. mask_layer( inpt  )\n",
    "   \n",
    "         mask = self. mask_layer.compute_mask(inpt)\n",
    "         end = timer()\n",
    "        # print('mask  duration' ,end - start )\n",
    "        \n",
    "         start = timer() \n",
    "         wi , out1   =  self.lstm_att( input_mask ,constants = seq_writer ,mask =mask)\n",
    "         end = timer()\n",
    "        # print('attention  duration' ,end - start )\n",
    "         \n",
    "            \n",
    "         if first_log:\n",
    "            print(\"window attention shape \" , wi.shape)\n",
    "            print('out1.shape' , out1.shape)\n",
    "            print(\"seq shape\" , seq_writer[0].shape) \n",
    "            print(\"writer shape\" , seq_writer[1].shape) \n",
    "         \n",
    "         #x = tf.concat([x, c], 2) \n",
    "         if first_log:\n",
    "            print(\"tf.concat([wi,out1,inpt]  x shape\" ,tf.concat([wi,out1,inpt] , axis = -1).shape)\n",
    "            \n",
    "         start = timer() \n",
    "         \n",
    "         #x   = self.lstm22(tf.concat([wi,out1,inpt] , axis = -1) , mask = mask)\n",
    "         out2 = self.l1(tf.concat([wi,out1,input_mask] , axis = -1) , mask = mask)\n",
    "         out3 = self.l2( tf.concat([wi,out2,input_mask] , axis = -1 ), mask = mask)\n",
    "         end = timer()\n",
    "         #print('lstm2 duration' ,end - start )\n",
    "        \n",
    "         if first_log:\n",
    "            print(\"out3  shape\" , out3.shape)#(32, 1200, 64)=>(batch,seq.length,unites+)\n",
    "         \n",
    "         start = timer()\n",
    "         self.gm_prediction = self.gm_layer(out3 ,mask = mask)\n",
    "         end = timer()\n",
    "         #print('gmm duration' ,end - start )   \n",
    "            \n",
    "         if first_log:\n",
    "            print('gm_prediction' , self.gm_prediction)\n",
    "         return self.gm_prediction ,mask\n",
    "  \n",
    "    def reset(self):\n",
    "         \n",
    "         self.lstm_att.reset_states()\n",
    "         self.l1.reset_states()\n",
    "         self.l2.reset_states()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_network_simple_generation0( array):\n",
    "  for i in range(array.shape[0] ):\n",
    "    if i%7!=0 :# to get 4 sample\n",
    "        continue\n",
    "    fig, ax = plt.subplots(figsize=(12, 3))#np.concatenate([np.cumsum(offsets[:, :2], axis=0), offsets[:, 2:3]], axis=1)\n",
    "    #plt.ylim((-50,50))\n",
    "    plt.title('network_out')\n",
    "    \n",
    "    print('array ',array.shape)\n",
    "   \n",
    "    one_net_strokes = array[i ,:,:]\n",
    "    \n",
    "    one_net_strokes =  tf.split(tf.transpose(one_net_strokes),3 ,axis =0)\n",
    "    one_net_strokes = np.asarray(one_net_strokes)\n",
    "    one_net_strokes =np.concatenate( [np.cumsum(one_net_strokes[:2, : , :], axis=2),\n",
    "                                       one_net_strokes[2:,: ,:]], axis=0)\n",
    "   \n",
    "    end_of_stroke =0\n",
    "    \n",
    "    stroke = [(0,0)]\n",
    "   \n",
    "    one_net_strokes = tf.squeeze(one_net_strokes)\n",
    "    one_net_strokes = tf.transpose(one_net_strokes)\n",
    "       \n",
    "    one_net_strokes= tf.dtypes.cast(one_net_strokes, tf.float32)\n",
    "    for indx , triple_coor in enumerate ( one_net_strokes):\n",
    "       \n",
    "        stroke.append((triple_coor[0], triple_coor[1]))\n",
    "        if ((triple_coor[2].numpy() == 1.0) or indx + 1 == len(one_net_strokes)) :\n",
    "            \n",
    "            coords = list(zip(*stroke))\n",
    "            end_of_stroke +=1\n",
    "            ax.plot(coords[0], coords[1], '-k')\n",
    "            \n",
    "            stroke = []\n",
    "    print('end of stroke',end_of_stroke)\n",
    "    \n",
    "#draw_network_simple_generation( rnn1.gm_prediction)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn11 = rnn_model( units , BATCH_SIZE , k_mixture ,GMM_mixtures  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2175e593a90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn11.load_weights(path_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_to_terminate(coor ,phi ,len_of_char) :\n",
    "    \n",
    "    current_attention = phi\n",
    "    if_afler_last_char = current_attention >= len_of_char - 1\n",
    "    \n",
    "    #print('current_attention {} ;len_of_char {}'.format(current_attention , len_of_char) )\n",
    "    \n",
    "    return ( if_afler_last_char  and  (coor[ 0 , 0 , 2] == 1) ) or (current_attention > len_of_char - 1) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 3), dtype=float32, numpy=array([[[0., 0., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def first_input(batch_size) :\n",
    "    i = [0. ,0. , 1.] * batch_size\n",
    "    i = tf.constant(i)\n",
    "    i = tf.reshape(i , (batch_size ,seq_length , 3))\n",
    "    \n",
    "    return i\n",
    "first_in =   first_input(BATCH_SIZE)\n",
    "first_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,number_of_writer , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_matrix = tf.constant( np.identity(number_of_writer , dtype=np.float32)) \n",
    "\n",
    "def random_writer():\n",
    "   \n",
    "    random_w = np.random.randint(0,number_of_writer , 1)\n",
    "    list_writer = writer_matrix[random_w[0]]\n",
    "    return tf.reshape(list_writer , (1,number_of_writer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #list of synthesis params :( segma_bias , alpha_bias , number of samples)\n",
    "  bias_numbers =  [(1., 5),(5., 5)]\n",
    "  \n",
    "  segma_bias =  tf.Variable(0 , dtype='float32' , trainable = False) \n",
    "  \n",
    "  alpha_bias =  tf.Variable(0 , dtype='float32' , trainable = False) \n",
    "  \n",
    " #variable to track the attention( on char sequence of string to write) to stop synthesis of points;used in function \"condition_to_terminate\"\n",
    "  new_phi = tf.Variable( 0,  dtype='int32' ,trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a number \"num_of_sample\" of words \"real_seq\" with the same params(biases)\n",
    "def hand_synthesis(real_seq ,num_of_sample ):\n",
    "    \n",
    "    global phi_track \n",
    "    global char_track\n",
    "    global rnn11\n",
    "    \n",
    "    list_of_handwrite = []\n",
    "   \n",
    "    \n",
    "    \n",
    "    for i in tf.range(num_of_sample) :\n",
    "      seq_to_write = real_seq #tf.expand_dims( , 0)\n",
    "     \n",
    "      writer =  random_writer()\n",
    "      len_of_char  = seq_to_write.shape[0]\n",
    "      \n",
    "      inp = first_in\n",
    "      phi_track = []\n",
    "      char_track = []\n",
    "      coordList = []\n",
    "        \n",
    "\n",
    "      while True:  #if  condition_to_terminate is false , generate an other coordinate  \n",
    "           \n",
    "            coord , _ = rnn11(inp  ,[seq_to_write , writer])  #synt_step\n",
    "            inp    = coord                                           #(1,1,3)\n",
    "            coordList.append(coord )\n",
    "           \n",
    "            if  condition_to_terminate(coord , new_phi ,len_of_char )  or len(coordList) > 750 :\n",
    "                break\n",
    "      rnn11.reset( )\n",
    "      \n",
    "      out = tf.reshape(tf.stack( coordList), [1, len(coordList), 3])   \n",
    "      list_of_handwrite.append(out)   \n",
    "     \n",
    "\n",
    "        \n",
    "    \n",
    "    return list_of_handwrite\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generated_to_png( list_of_handwrite  , seq_write ):\n",
    " \n",
    " \n",
    " for   array in list_of_handwrite :\n",
    "    \n",
    "    stroke = []\n",
    "    \n",
    "    stringToWrite =  tostring (seq_write)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 3))   \n",
    "    \n",
    "    one_net_strokes = tf.squeeze(array )\n",
    "    #print('one_net_strokes' , one_net_strokes)\n",
    "    \n",
    "    one_net_strokes =tf.concat( [tf.cumsum(one_net_strokes[:, :2 ], axis=0),\n",
    "                                       one_net_strokes[:, 2: ]], axis=1)\n",
    "   \n",
    "    \n",
    "    #  Matrix transormation to add skew to letters( by degree ) : \n",
    "    \n",
    "#     theta = degree * np.pi/180\n",
    "#     A = np.array([[np.cos(-theta), 0], [np.sin(-theta), 1]])\n",
    "#     one_net_strokes[:, :2] = np.dot(one_net_strokes[:, :2], A) \n",
    "    \n",
    "   \n",
    "    for indx , triple_coor in enumerate ( one_net_strokes):\n",
    "    \n",
    "        \n",
    "        stroke.append((triple_coor[0], triple_coor[1]))\n",
    "        \n",
    "        if ((triple_coor[2] == 1.0  and indx != 0 ) or indx + 1 == len(one_net_strokes)) :\n",
    "            \n",
    "            coords = list(zip(*stroke))\n",
    "\n",
    "            plt.axis('off')\n",
    "            \n",
    "            ax.plot(coords[0], coords[1], '-k')\n",
    "            \n",
    "            stroke = []\n",
    "        \n",
    "    save_png( plt , stringToWrite )\n",
    "    plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_png(plt , stringToWrite ) :\n",
    "    pt = path_tosave_image + stringToWrite.strip()\n",
    "   \n",
    "    pathlib.Path(pt).mkdir(parents=True, exist_ok=True) \n",
    "    \n",
    "    cpt = sum([len(files) for _ ,_ , files in os.walk(pt)])\n",
    "    \n",
    "    plt.savefig( pt+ '/' + str(cpt ) +'.png' ,  bbox_inches = 0 )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tostring (seq_write) :\n",
    "    \n",
    "    rrrr=tf.math.argmax(seq_write , axis = -1)#.numpy().astype(np.int32)\n",
    "    \n",
    "    ooo = [[drawing.alphabet[n] for n in i if n !=0]for i in rrrr]\n",
    "    \n",
    "    stringToWrite = [ ''.join(k) for k in ooo]\n",
    "    return stringToWrite[0] \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "syntesis duration of string is 41.44259749999992\n",
      "10\n",
      "syntesis duration of string is 68.36862829999995\n",
      "20\n",
      "syntesis duration of string is 29.975505599999906\n",
      "30\n",
      "syntesis duration of string is 63.19640530000015\n",
      "40\n",
      "syntesis duration of string is 34.07274009999992\n",
      "50\n",
      "syntesis duration of string is 35.521002299999964\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-d3f03d285694>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m      \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m      \u001b[0mlist_of_handwrite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhand_synthesis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_sample\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m      \u001b[0mgenerated_to_png\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mlist_of_handwrite\u001b[0m  \u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmed\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-67756a8630ff>\u001b[0m in \u001b[0;36mhand_synthesis\u001b[1;34m(real_seq, num_of_sample)\u001b[0m\n\u001b[0;32m     24\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m#if  condition_to_terminate is false , generate an other coordinate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mcoord\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn11\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m  \u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_to_write\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#synt_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[0minp\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mcoord\u001b[0m                                           \u001b[1;31m#(1,1,3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mcoordList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoord\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    967\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 968\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-c5d4fd4ec545>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inpt, seq_writer)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m          \u001b[1;31m#x   = self.lstm22(tf.concat([wi,out1,inpt] , axis = -1) , mask = mask)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m          \u001b[0mout2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m          \u001b[0mout3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m          \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    967\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 968\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1181\u001b[0m               **gpu_lstm_kwargs)\n\u001b[0;32m   1182\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m           last_output, outputs, new_h, new_c, runtime = standard_lstm(\n\u001b[0m\u001b[0;32m   1184\u001b[0m               **normal_lstm_kwargs)\n\u001b[0;32m   1185\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mstandard_lstm\u001b[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, activation, recurrent_activation, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1310\u001b[1;33m   last_output, outputs, new_states = K.rnn(\n\u001b[0m\u001b[0;32m   1311\u001b[0m       \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m       \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minit_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_c\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mrnn\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   4089\u001b[0m     \u001b[1;31m# output_time_zero is used to determine the cell output shape and its dtype.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4090\u001b[0m     \u001b[1;31m# the value is discarded.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4091\u001b[1;33m     output_time_zero, _ = step_function(\n\u001b[0m\u001b[0;32m   4092\u001b[0m         input_time_zero, tuple(initial_states) + tuple(constants))\n\u001b[0;32m   4093\u001b[0m     output_ta = tuple(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[0;32m   1302\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecurrent_activation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecurrent_activation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mc_tm1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m     \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecurrent_activation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    985\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 987\u001b[1;33m           y = ops.convert_to_tensor_v2(\n\u001b[0m\u001b[0;32m    988\u001b[0m               y, dtype_hint=x.dtype.base_dtype, name=\"y\")\n\u001b[0;32m    989\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m   \"\"\"\n\u001b[1;32m-> 1278\u001b[1;33m   return convert_to_tensor(\n\u001b[0m\u001b[0;32m   1279\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpreferred_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1328\u001b[1;33m         ret = conversion_func(\n\u001b[0m\u001b[0;32m   1329\u001b[0m             value, dtype=preferred_dtype, name=name, as_ref=as_ref)\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[1;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   1823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1824\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_dense_var_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1825\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_var_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1240\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munused_other\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mvalue\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    548\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_existing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_as_graph_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[1;34m()\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m       result = gen_resource_variable_ops.read_variable_op(self._handle,\n\u001b[0m\u001b[0;32m    636\u001b[0m                                                           self._dtype)\n\u001b[0;32m    637\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    466\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    469\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ReadVariableOp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m         tld.op_callbacks, resource, \"dtype\", dtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "  start0 = timer()\n",
    "    \n",
    "#the handwriting syntesis was stopped at index 50 .lastIndex = 50 \n",
    "  param_counter = 0\n",
    "  for s_bias  , num in bias_numbers :           # loop on each param of handwrting syntesis : bias\n",
    "    \n",
    "    segma_bias.assign(s_bias)\n",
    "   \n",
    "    number_of_sample = num\n",
    "    \n",
    "    first_log = False \n",
    "    for indx ,  med in enumerate(real_seqs):     #get handwriting for each med_name in list of tensors\n",
    "       \n",
    "    \n",
    "      if indx < lastIndex and s_bias == 1.0 :\n",
    "            continue\n",
    "            \n",
    "       start = timer()\n",
    "       list_of_handwrite = hand_synthesis(med, number_of_sample )\n",
    "   \n",
    "       generated_to_png( list_of_handwrite  ,tf.expand_dims(med , 0))\n",
    "       if indx % 10 == 0 :\n",
    "            tf.print(indx)\n",
    "            end = timer()\n",
    "            tf.print('syntesis duration of string is' ,end - start )\n",
    "    param_counter += 1   \n",
    "       \n",
    "  end0 = timer()\n",
    "  print('syntesis duration' ,end0 - start0 )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_seqs_np = [t.numpy() for t in real_seqs]\n",
    "# np.save('real_seqs_medicament2_saved.npy' ,real_seqs_np ,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(phi_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_plt = tf.convert_to_tensor(phi_track)\n",
    "phi_plt = tf.squeeze(phi_plt)\n",
    "phi_plt = tf.transpose(phi_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(tf.math.argmax(tf.squeeze(tf.transpose(phi_track)) ,axis = 0 ))\n",
    "#plt.axis([0, 1, 0, 10000])\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "list_chara = [v for i, v in enumerate(char_track) if i == 0 or v != char_track[i-1]]\n",
    "ax.set_yticks(np.arange(0,len(list_chara)))\n",
    "\n",
    "ax.set_yticklabels(list_chara)\n",
    "im = ax.imshow(phi_plt , aspect='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(char_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(char_track)\n",
    "#plt.axis([0, 1, 0, 10000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toTensor = tf.convert_to_tensor(lst_alpha)\n",
    "toTensor =tf.squeeze( toTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toTensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches (30,200)\n",
    "# plt.xlabel('time step')\n",
    "# plt.ylabel('20 gmm activation')\n",
    "im = plt.imshow(tf.transpose(toTensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handw = tf.convert_to_tensor(list_of_handwrite)\n",
    "hand = tf.squeeze(handw)\n",
    "hand = hand[: , 0:2]\n",
    "handx  = hand[: , 0]*100\n",
    "handy = hand[: , 1]*100\n",
    "\n",
    "handx = tf.cumsum(handx , axis=0)\n",
    "handy = tf.cumsum(handy , axis=0)\n",
    "# handx  = tf.clip_by_value(handx ,clip_value_min = -200 , clip_value_max = 200)\n",
    "# handy  = tf.clip_by_value(handy , clip_value_min = -250 ,clip_value_max = 250)\n",
    "handx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lst_logprob1 = tf.convert_to_tensor(tf.math.log(lst_logprob))\n",
    "lst_logprob1 = tf.squeeze(lst_logprob1)\n",
    "lst_logprob1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches (80,20)\n",
    "ax.set_facecolor(\"black\")\n",
    "plt.scatter(handx, handy, s= 128000* (1/lst_logprob1.numpy() )**3  ,  facecolor='yellow' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
